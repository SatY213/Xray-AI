1. Dataset Organization

Got the Chest X-Ray dataset (Normal / Pneumonia).

Structured into train/, val/, and test/ folders.

Each folder has subfolders for the two classes.

2. Data Preprocessing

Defined transforms (resize, normalization, augmentation like flips & rotations).

Created PyTorch DataLoaders to feed data in batches.

3. Model Definition

Used ResNet18 (pre-trained CNN) as the backbone.

Replaced the last layer to predict 2 classes (Normal vs Pneumonia).

4. Optimization

Defined loss function: nn.CrossEntropyLoss()

Tells the model how wrong its predictions are.

Defined optimizer: Adam with learning rate 1e-4

Updates model weights to reduce loss.

5. Training

Training loop: forward pass â†’ loss calculation â†’ backpropagation â†’ weight update.

Validation loop (no weight updates).

Used accuracy as evaluation metric.

Tracked best model based on validation accuracy.

6. Evaluation

After training, we saved the best model weights.

Accuracy and loss metrics tell us how well the model learned.

(Later we can evaluate on the test set to simulate real-world performance).

7. Saving the Model

Saved model as pneumonia_resnet18.pt.

Next time, we can load the model directly instead of retraining from scratch.

That means youâ€™ve basically done a full Data Science project lifecycle already.
You now understand:

Data organization

Preprocessing

Model definition

Optimization (loss + optimizer)

Training

Evaluation

Saving for reuse

ðŸ‘‰ The only big steps left are:

Milestone 4: Evaluate on test set (final performance).

Milestone 5: Build inference script (predict on new X-ray images).

Milestone 6 (optional): Visualization (accuracy/loss curves, confusion matrix, Grad-CAM heatmaps).